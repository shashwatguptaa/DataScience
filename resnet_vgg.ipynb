{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashwatguptaa/DataScience/blob/main/resnet_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTy2hbMR0aK2"
      },
      "outputs": [],
      "source": [
        "!pip install -qU torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74HtdeARolvg",
        "outputId": "2829f4b3-b4b5-4ef3-d9df-72f7656f7e43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shashwatguptaa/DataScience.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vXrZRhFpSE7",
        "outputId": "9c1b2c71-bd7a-48ed-8665-d908048be54a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DataScience'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 26 (delta 6), reused 21 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (26/26), 87.70 KiB | 501.00 KiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0h8yXSmpcz_",
        "outputId": "3b2d9e7a-7e7f-4bad-d7b1-403108ef914d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVlHQT6f8sxI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from abc import ABC,abstractmethod\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P27P6_o59rCq"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,root_dir,transform=None,target_size=(224,224),max_image_per_class=1000):\n",
        "    self.root_dir=root_dir\n",
        "    self.transform=transform\n",
        "    self.target_size=target_size\n",
        "    self.max_image=max_image_per_class\n",
        "    # self.classes=os.listdir(root_dir)\n",
        "    selected_classes = ['cloudy', 'desert']\n",
        "    self.classes = [cls for cls in os.listdir(root_dir) if cls in selected_classes]\n",
        "    self.classes_indx={cls:indx for indx,cls in enumerate(self.classes)}\n",
        "    self.samples=[]\n",
        "    class_image_sizes=defaultdict(list)\n",
        "\n",
        "    for classes in self.classes:\n",
        "      class_path=os.path.join(root_dir,classes)\n",
        "      img_files=os.listdir(class_path)\n",
        "      if(len(img_files)>self.max_image):\n",
        "          img_files=img_files[:self.max_image]\n",
        "      for img_name in img_files:\n",
        "        img_path=os.path.join(class_path,img_name)\n",
        "        self.samples.append((img_path,self.classes_indx[classes]))\n",
        "\n",
        "    for img_path, class_idx in self.samples:\n",
        "      with Image.open(img_path) as img:\n",
        "          width, height = img.size\n",
        "          class_name = self.classes[class_idx]\n",
        "          class_image_sizes[class_name].append((width, height))\n",
        "\n",
        "    for class_name, sizes in class_image_sizes.items():\n",
        "      print(f\"\\nClass: {class_name}\")\n",
        "      print(f\"Total images: {len(sizes)}\")\n",
        "      size_counts = defaultdict(int)\n",
        "      for size in sizes:\n",
        "          size_counts[size] += 1\n",
        "      for size, count in size_counts.items():\n",
        "          print(f\"  Size {size}: {count} images\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    image_path,label=self.samples[idx]\n",
        "    image=Image.open(image_path).convert('RGB')\n",
        "    image=image.resize(self.target_size)\n",
        "\n",
        "    if self.transform:\n",
        "      image=self.transform(image)\n",
        "\n",
        "    return image,label\n",
        "\n",
        "def createDataLoader(dataset,batch_size=32,train_size=0.7,val_size=0.2,test_size=0.1):\n",
        "    total_size=len(dataset)\n",
        "    train_size=int(train_size*total_size)\n",
        "    val_size=int(val_size*total_size)\n",
        "    test_size=total_size-train_size-val_size\n",
        "\n",
        "    train_dataset,val_dataset,test_dataset=random_split(dataset,[train_size,val_size,test_size])\n",
        "\n",
        "    train_dataset=DataLoader(train_dataset,batch_size,shuffle=True)\n",
        "    val_dataset=DataLoader(val_dataset,batch_size,shuffle=False)\n",
        "    test_dataset=DataLoader(test_dataset,batch_size,shuffle=False)\n",
        "\n",
        "    return train_dataset,val_dataset,test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOWy8CW-FMcV"
      },
      "outputs": [],
      "source": [
        "class BaseModel(ABC,nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "      super().__init__()\n",
        "      self.num_classes = num_classes\n",
        "\n",
        "  @abstractmethod\n",
        "  def forward(self,x):\n",
        "      pass\n",
        "\n",
        "  def get_optimizer(self,lr=0.001,optimizer_type='adam'):\n",
        "    if(optimizer_type.lower()=='adam'):\n",
        "      return optim.Adam(self.parameters(),lr=lr)\n",
        "    elif(optimizer_type.lower()=='sgd'):\n",
        "      return optim.SGD(self.parameters(),lr=lr)\n",
        "    else:\n",
        "      raise ValueError(\"Optimizer not supported\")\n",
        "\n",
        "  def get_criterion(self):\n",
        "    return nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSj0yDKbJQGm"
      },
      "outputs": [],
      "source": [
        "class CustomResnet(BaseModel):\n",
        "  def __init__(self,num_features,pretrained=True,freeze_backbone=False):\n",
        "    super(CustomResnet,self).__init__(num_features)\n",
        "    self.resnet=models.resnet18(pretrained=pretrained)\n",
        "\n",
        "    # if freeze_backbone:\n",
        "    #   for param in self.resnet.parameters():\n",
        "    #     param.requires_grad= False\n",
        "\n",
        "    self.resnet.fc=nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(self.resnet.fc.in_features,512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512,num_features)\n",
        "    )\n",
        "\n",
        "    # if freeze_backbone:\n",
        "    #     for name, param in self.resnet.named_parameters():\n",
        "    #         if not name.startswith('fc'):\n",
        "    #             param.requires_grad = False\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ruN-XkUmSZR"
      },
      "outputs": [],
      "source": [
        "class CustomVgg(BaseModel):\n",
        "  def __init__(self,num_features,pretrained=True,freeze_backbone=False):\n",
        "    super(CustomVgg,self).__init__(num_features)\n",
        "    self.vgg=models.vgg16(pretrained=pretrained)\n",
        "\n",
        "    # if freeze_backbone:\n",
        "    #   for param in self.vgg.parameters():\n",
        "    #     param.requires_grad= False\n",
        "\n",
        "    self.vgg.classifier=nn.Sequential(\n",
        "        nn.Linear(25088,4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(4096,1024),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(1024,num_features)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.vgg(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9-iHJydw9Ma"
      },
      "outputs": [],
      "source": [
        "class CustomCNN(BaseModel):\n",
        "  def __init__(self,num_features,input_channels=3):\n",
        "    super(CustomCNN,self).__init__(num_features)\n",
        "    self.input_channels=input_channels\n",
        "    self.features=nn.Sequential(\n",
        "        nn.Conv2d(input_channels,64,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.AdaptiveAvgPool2d((7,7))\n",
        "    )\n",
        "\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512*7*7,4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(4096,1024),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(1024,num_features)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.features(x)\n",
        "    x=torch.flatten(x, 1)\n",
        "    x=self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_vfRXfL0VjY"
      },
      "outputs": [],
      "source": [
        "class ModelFactory:\n",
        "  @staticmethod\n",
        "  def create_model(model_name,num_features,**kwargs):\n",
        "    if(model_name.lower() == 'resnet'):\n",
        "      return CustomResnet(num_features,**kwargs)\n",
        "    elif(model_name.lower() == 'vgg'):\n",
        "      return CustomVgg(num_features,**kwargs)\n",
        "    elif(model_name.lower() == 'cnn'):\n",
        "      return CustomCNN(num_features,**kwargs)\n",
        "    else:\n",
        "      raise ValueError('This model is not defined.')\n",
        "\n",
        "class Trainer:\n",
        "  def __init__(self,model,train_loader,val_loader,device='cuda'):\n",
        "    self.model=model.to(device)\n",
        "    self.train_loader=train_loader\n",
        "    self.val_loader=val_loader\n",
        "    self.device=device\n",
        "    self.optimiser=model.get_optimizer()\n",
        "    self.criterion=model.get_criterion()\n",
        "\n",
        "    self.train_losses = []\n",
        "    self.val_losses = []\n",
        "    self.train_accuracies = []\n",
        "    self.val_accuracies = []\n",
        "\n",
        "\n",
        "  def train_epoch(self):\n",
        "    self.model.train()\n",
        "    running_loss=0.0\n",
        "    correct=0\n",
        "    total=0\n",
        "    for inputs,label in self.train_loader:\n",
        "      inputs=inputs.to(self.device)\n",
        "      label = label.to(self.device)\n",
        "\n",
        "      self.optimiser.zero_grad()\n",
        "      output=self.model(inputs)\n",
        "      # print(output, \": The output hehehehe\\n\")\n",
        "      loss=self.criterion(output,label)\n",
        "      self.optimiser.step()\n",
        "\n",
        "      running_loss+=loss.item()\n",
        "      _,predicted=torch.max(output.data,1)\n",
        "      total+=label.size(0)\n",
        "      correct+=(predicted == label).sum().item()\n",
        "    return running_loss/len(self.train_loader),100*correct/total\n",
        "\n",
        "  def validate(self):\n",
        "        self.model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in self.val_loader:\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        return running_loss / len(self.val_loader), 100 * correct / total\n",
        "\n",
        "  def train(self, epochs,save_path='best_model.pth'):\n",
        "        best_train_acc=0.0\n",
        "        best_val_acc = 0.0\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = self.train_epoch()\n",
        "            val_loss, val_acc = self.validate()\n",
        "\n",
        "            self.train_losses.append(train_loss)\n",
        "            self.val_losses.append(val_loss)\n",
        "            self.train_accuracies.append(train_acc)\n",
        "            self.val_accuracies.append(val_acc)\n",
        "\n",
        "            # if val_acc > best_val_acc:\n",
        "            #   best_val_acc = val_acc\n",
        "            #   torch.save(self.model.state_dict(), save_path)\n",
        "            #   print(f\"Best model saved with val acc: {val_acc:.2f}%\")\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{epochs}]')\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "            print('-' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVeVFsmQWjiX"
      },
      "outputs": [],
      "source": [
        "def plot_training_curves(trainer):\n",
        "    epochs = range(1, len(trainer.train_losses) + 1)\n",
        "\n",
        "    # Loss plot\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, trainer.train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, trainer.val_losses, label='Val Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, trainer.train_accuracies, label='Train Acc')\n",
        "    plt.plot(epochs, trainer.val_accuracies, label='Val Acc')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Accuracy Curve')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXyYTFCnfbDV",
        "outputId": "753a851f-f6b2-4fd9-e4f6-89812780e5eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class: cloudy\n",
            "Total images: 1000\n",
            "  Size (256, 256): 1000 images\n",
            "\n",
            "Class: desert\n",
            "Total images: 1000\n",
            "  Size (256, 256): 1000 images\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    # transforms.Resize((64, 64)),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "dataset = CustomDataset(\n",
        "    root_dir=\"/content/drive/MyDrive/Untitled Folder/unzipped_data/data\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader, val_loader, test_loader = createDataLoader(dataset, batch_size=32)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlpyZrRX37G8",
        "outputId": "1f481b38-4d89-4997-feb1-79ced5ee4fa3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 141MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "          Dropout-68                  [-1, 512]               0\n",
            "           Linear-69                  [-1, 512]         262,656\n",
            "             ReLU-70                  [-1, 512]               0\n",
            "          Dropout-71                  [-1, 512]               0\n",
            "           Linear-72                    [-1, 2]           1,026\n",
            "           ResNet-73                    [-1, 2]               0\n",
            "================================================================\n",
            "Total params: 11,440,194\n",
            "Trainable params: 11,440,194\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.80\n",
            "Params size (MB): 43.64\n",
            "Estimated Total Size (MB): 107.02\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 126MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 1024]       4,195,328\n",
            "             ReLU-37                 [-1, 1024]               0\n",
            "          Dropout-38                 [-1, 1024]               0\n",
            "           Linear-39                    [-1, 2]           2,050\n",
            "              VGG-40                    [-1, 2]               0\n",
            "================================================================\n",
            "Total params: 121,676,610\n",
            "Trainable params: 121,676,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.70\n",
            "Params size (MB): 464.16\n",
            "Estimated Total Size (MB): 683.44\n",
            "----------------------------------------------------------------\n",
            "Training ResNet:\n",
            "Epoch [1/20]\n",
            "Train Loss: 0.7641, Train Acc: 45.36%\n",
            "Val Loss: 0.7408, Val Acc: 51.75%\n",
            "--------------------------------------------------\n",
            "Epoch [2/20]\n",
            "Train Loss: 0.7612, Train Acc: 48.07%\n",
            "Val Loss: 0.7400, Val Acc: 52.50%\n",
            "--------------------------------------------------\n",
            "Epoch [3/20]\n",
            "Train Loss: 0.7876, Train Acc: 44.79%\n",
            "Val Loss: 0.7467, Val Acc: 52.00%\n",
            "--------------------------------------------------\n",
            "Epoch [4/20]\n",
            "Train Loss: 0.7655, Train Acc: 46.64%\n",
            "Val Loss: 0.7396, Val Acc: 52.50%\n",
            "--------------------------------------------------\n",
            "Epoch [5/20]\n",
            "Train Loss: 0.7865, Train Acc: 43.14%\n",
            "Val Loss: 0.7467, Val Acc: 51.00%\n",
            "--------------------------------------------------\n",
            "Epoch [6/20]\n",
            "Train Loss: 0.7857, Train Acc: 43.21%\n",
            "Val Loss: 0.7427, Val Acc: 51.75%\n",
            "--------------------------------------------------\n",
            "Epoch [7/20]\n",
            "Train Loss: 0.7897, Train Acc: 43.14%\n",
            "Val Loss: 0.7428, Val Acc: 52.25%\n",
            "--------------------------------------------------\n",
            "Epoch [8/20]\n",
            "Train Loss: 0.7844, Train Acc: 43.79%\n",
            "Val Loss: 0.7495, Val Acc: 52.50%\n",
            "--------------------------------------------------\n",
            "Epoch [9/20]\n",
            "Train Loss: 0.7785, Train Acc: 45.29%\n",
            "Val Loss: 0.7533, Val Acc: 52.00%\n",
            "--------------------------------------------------\n",
            "Epoch [10/20]\n",
            "Train Loss: 0.7791, Train Acc: 46.07%\n",
            "Val Loss: 0.7471, Val Acc: 52.25%\n",
            "--------------------------------------------------\n",
            "Epoch [11/20]\n",
            "Train Loss: 0.7778, Train Acc: 43.21%\n",
            "Val Loss: 0.7436, Val Acc: 51.75%\n",
            "--------------------------------------------------\n",
            "Epoch [12/20]\n",
            "Train Loss: 0.7788, Train Acc: 44.57%\n",
            "Val Loss: 0.7502, Val Acc: 51.75%\n",
            "--------------------------------------------------\n",
            "Epoch [13/20]\n",
            "Train Loss: 0.7901, Train Acc: 42.79%\n",
            "Val Loss: 0.7488, Val Acc: 52.00%\n",
            "--------------------------------------------------\n",
            "Epoch [14/20]\n",
            "Train Loss: 0.7714, Train Acc: 46.07%\n",
            "Val Loss: 0.7492, Val Acc: 52.25%\n",
            "--------------------------------------------------\n",
            "Epoch [15/20]\n",
            "Train Loss: 0.7741, Train Acc: 43.71%\n",
            "Val Loss: 0.7457, Val Acc: 52.00%\n",
            "--------------------------------------------------\n",
            "Epoch [16/20]\n",
            "Train Loss: 0.7903, Train Acc: 44.00%\n",
            "Val Loss: 0.7503, Val Acc: 52.50%\n",
            "--------------------------------------------------\n",
            "Epoch [17/20]\n",
            "Train Loss: 0.7689, Train Acc: 46.14%\n",
            "Val Loss: 0.7496, Val Acc: 51.50%\n",
            "--------------------------------------------------\n",
            "Epoch [18/20]\n",
            "Train Loss: 0.7855, Train Acc: 43.57%\n",
            "Val Loss: 0.7487, Val Acc: 52.75%\n",
            "--------------------------------------------------\n",
            "Epoch [19/20]\n",
            "Train Loss: 0.7844, Train Acc: 43.43%\n",
            "Val Loss: 0.7469, Val Acc: 52.00%\n",
            "--------------------------------------------------\n",
            "Epoch [20/20]\n",
            "Train Loss: 0.7883, Train Acc: 45.29%\n",
            "Val Loss: 0.7519, Val Acc: 51.75%\n",
            "--------------------------------------------------\n",
            "\n",
            "Training VGG:\n",
            "Epoch [1/20]\n",
            "Train Loss: 0.6927, Train Acc: 48.43%\n",
            "Val Loss: 0.6915, Val Acc: 50.00%\n",
            "--------------------------------------------------\n",
            "Epoch [2/20]\n",
            "Train Loss: 0.6917, Train Acc: 49.71%\n",
            "Val Loss: 0.6919, Val Acc: 52.75%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "resnet_model = ModelFactory.create_model('resnet', num_features=2, pretrained=True, freeze_backbone=True)\n",
        "resnet_model.to(device)\n",
        "summary(resnet_model, input_size=(3, 224, 224))\n",
        "vgg_model = ModelFactory.create_model('vgg', num_features=2, pretrained=True, freeze_backbone=True)\n",
        "vgg_model.to(device)\n",
        "summary(vgg_model, input_size=(3, 224, 224))\n",
        "custom_model = ModelFactory.create_model('cnn', num_features=2)\n",
        "\n",
        "resnet_trainer = Trainer(resnet_model, train_loader, val_loader, device)\n",
        "vgg_trainer = Trainer(vgg_model, train_loader, val_loader, device)\n",
        "custom_trainer = Trainer(custom_model, train_loader, val_loader, device)\n",
        "\n",
        "print(\"Training ResNet:\")\n",
        "resnet_trainer.train(epochs=20)\n",
        "\n",
        "print(\"\\nTraining VGG:\")\n",
        "vgg_trainer.train(epochs=20)\n",
        "\n",
        "print(\"\\nTraining Custom CNN:\")\n",
        "custom_trainer.train(epochs=20)\n",
        "\n",
        "\n",
        "plot_training_curves(resnet_trainer)\n",
        "plot_training_curves(vgg_trainer)\n",
        "plot_training_curves(custom_trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEoYdXpa6L8j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1TkhleBfSbqmdSky_X22Ja-C0Lo-XBn2Z",
      "authorship_tag": "ABX9TyNlkqID4LfCH9xOWlhAsvbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}